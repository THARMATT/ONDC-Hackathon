{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c6c87b",
   "metadata": {},
   "source": [
    "# WE have created the encrypted data to be shared with other buyer NPs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46992a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption completed and files are ready to be shared!\n"
     ]
    }
   ],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "import pandas as pd\n",
    "\n",
    "def encrypt_data(data, key):\n",
    "    cipher = Fernet(key)\n",
    "    encrypted_data = cipher.encrypt(data.encode())\n",
    "    return encrypted_data\n",
    "\n",
    "# Import the dataset for Selling App 1\n",
    "selling_app_1_dataset = pd.read_csv(\"Customer_data_1.csv\")\n",
    "\n",
    "# Select specific columns from the dataset\n",
    "selected_columns = ['Customer ID', 'Cart Items', 'Purchase History', 'Search History','Seller Name']\n",
    "selected_data = selling_app_1_dataset[selected_columns]\n",
    "\n",
    "# Convert the selected data to CSV format\n",
    "selected_data_csv = selected_data.to_csv(index=False)\n",
    "\n",
    "# Generate a random secret key for encryption\n",
    "secret_key = Fernet.generate_key()\n",
    "\n",
    "# Encrypt the selected data for Selling App 1\n",
    "encrypted_data = encrypt_data(selected_data_csv, secret_key)\n",
    "\n",
    "# Save the encrypted data to a file\n",
    "with open(\"encrypted_codus_data.bin\", \"wb\") as file:\n",
    "    file.write(encrypted_data)\n",
    "\n",
    "# Save the encryption key to a file\n",
    "with open(\"encryption_key_codus.key\", \"wb\") as key_file:\n",
    "    key_file.write(secret_key)\n",
    "\n",
    "print(\"Encryption completed and files are ready to be shared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5275d5b",
   "metadata": {},
   "source": [
    "# We have collected the data from other buyer apps and decrypted it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13047c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decryption completed and CSV file saved as 'decrypted_indiamart_data.csv'.\n",
      "Decryption completed and CSV file saved as 'decrypted_pincode_data.csv'.\n",
      "Decryption completed and CSV file saved as 'decrypted_zonalmart_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def decrypt_data(encrypted_data, key):\n",
    "    cipher = Fernet(key)\n",
    "    decrypted_data = cipher.decrypt(encrypted_data)\n",
    "    return decrypted_data.decode()\n",
    "\n",
    "def decrypt_and_save(decryption_key_file, encrypted_data_file, output_csv_file):\n",
    "    # Read the encryption key from the file\n",
    "    with open(decryption_key_file, \"rb\") as key_file:\n",
    "        secret_key = key_file.read()\n",
    "\n",
    "    # Read the encrypted data from the file\n",
    "    with open(encrypted_data_file, \"rb\") as file:\n",
    "        encrypted_data = file.read()\n",
    "\n",
    "    # Decrypt the data\n",
    "    decrypted_csv = decrypt_data(encrypted_data, secret_key)\n",
    "\n",
    "    # Convert the decrypted data to a pandas DataFrame\n",
    "    decrypted_dataframe = pd.read_csv(io.StringIO(decrypted_csv))\n",
    "\n",
    "    # Save the decrypted data to a CSV file\n",
    "    decrypted_dataframe.to_csv(output_csv_file, index=False)\n",
    "\n",
    "    print(f\"Decryption completed and CSV file saved as '{output_csv_file}'.\")\n",
    "\n",
    "# Example usage for multiple files decryption\n",
    "decrypt_and_save(\"C:\\\\Users\\\\mahal\\\\Desktop\\\\BUILD_FOR_BHARAT\\\\BUILD_FOR_BHARAT_SCALED\\\\IndiaMart\\\\encryption_key_indiamart.key\", \"C:\\\\Users\\\\mahal\\\\Desktop\\\\BUILD_FOR_BHARAT\\\\BUILD_FOR_BHARAT_SCALED\\\\IndiaMart\\\\encrypted_indiamart_data.bin\", \"decrypted_indiamart_data.csv\")\n",
    "decrypt_and_save(\"C:\\\\Users\\\\mahal\\\\Desktop\\\\BUILD_FOR_BHARAT\\\\BUILD_FOR_BHARAT_SCALED\\\\Pincode\\\\encryption_key_pincode.key\", \"C:\\\\Users\\\\mahal\\\\Desktop\\\\BUILD_FOR_BHARAT\\\\BUILD_FOR_BHARAT_SCALED\\\\Pincode\\\\encrypted_pincode_data.bin\", \"decrypted_pincode_data.csv\")\n",
    "decrypt_and_save(\"C:\\\\Users\\\\mahal\\\\Desktop\\\\BUILD_FOR_BHARAT\\\\BUILD_FOR_BHARAT_SCALED\\\\ZonalWay\\\\encryption_key_zonalmart.key\", \"C:\\\\Users\\\\mahal\\\\Desktop\\\\BUILD_FOR_BHARAT\\\\BUILD_FOR_BHARAT_SCALED\\\\ZonalWay\\\\encrypted_zonalmart_data.bin\", \"decrypted_zonalmart_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451df758",
   "metadata": {},
   "source": [
    "# Now we need to merge the data of all the buyer apps so that we can apply recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11eefede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated dataset created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read your existing dataset\n",
    "your_data = pd.read_csv(\"customer_data_1.csv\")\n",
    "\n",
    "# Read the collected data from the other three apps\n",
    "app2_data = pd.read_csv(\"decrypted_indiamart_data.csv\")\n",
    "app3_data = pd.read_csv(\"decrypted_pincode_data.csv\")\n",
    "app4_data = pd.read_csv(\"decrypted_zonalmart_data.csv\")\n",
    "\n",
    "# Combine all datasets into a single list\n",
    "all_datasets = [your_data, app2_data, app3_data, app4_data]\n",
    "\n",
    "# Merge all datasets on 'Customer ID' to combine data for each customer\n",
    "merged_data = pd.concat(all_datasets).groupby('Customer ID').agg(lambda x: ','.join(set(x.dropna().astype(str))))\n",
    "\n",
    "# Save the consolidated dataset to a new CSV file\n",
    "merged_data.to_csv(\"Consolidated_data.csv\")\n",
    "\n",
    "print(\"Consolidated dataset created and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0882ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter customer ID: 15\n",
      "\n",
      "We have top 5 products liked by you!\n",
      "\n",
      "                   Product Name  Seller Name\n",
      "21            Whole Wheat Penne    FreshMart\n",
      "31            Whole Wheat Bread    GreenMart\n",
      "18                Coconut Water    FreshMart\n",
      "46  Whole Grain Sourdough Bread  NatureFresh\n",
      "40            Whole Grain Pasta    GreenMart\n",
      "\n",
      "Wait for a while!\n",
      "Your recommendations will be sent to sellers so that you can get personalised offers by them!\n",
      "\n",
      "Surprise!! Sellers have given you some discounts!!\n",
      " \n",
      "╒═════════════════════════════╤═══════════════╤════════════════╕\n",
      "│ Product Name                │ Seller Name   │ Discount       │\n",
      "╞═════════════════════════════╪═══════════════╪════════════════╡\n",
      "│ Whole Wheat Penne           │ FreshMart     │ Fast Dilevery! │\n",
      "├─────────────────────────────┼───────────────┼────────────────┤\n",
      "│ Whole Wheat Bread           │ GreenMart     │ 10%            │\n",
      "├─────────────────────────────┼───────────────┼────────────────┤\n",
      "│ Coconut Water               │ FreshMart     │ Fast Dilevery! │\n",
      "├─────────────────────────────┼───────────────┼────────────────┤\n",
      "│ Whole Grain Sourdough Bread │ NatureFresh   │ Free Dilevery! │\n",
      "├─────────────────────────────┼───────────────┼────────────────┤\n",
      "│ Whole Grain Pasta           │ GreenMart     │ 10%            │\n",
      "╘═════════════════════════════╧═══════════════╧════════════════╛\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Sample product data and customer data (replace with your actual data)\n",
    "product_data = pd.read_csv(\"product_data.csv\")\n",
    "customer_data = pd.read_csv(\"consolidated_data.csv\")\n",
    "\n",
    "# Function to preprocess customer interactions\n",
    "def preprocess_interactions(interactions):\n",
    "    # Split the interactions string into a list of items\n",
    "    return interactions.split(',')\n",
    "\n",
    "# Preprocess customer interactions\n",
    "customer_data['Interactions'] = customer_data['Cart Items'] + ',' + customer_data['Purchase History'] + ',' + customer_data['Search History']\n",
    "customer_data['Interactions'] = customer_data['Interactions'].apply(preprocess_interactions)\n",
    "\n",
    "# Function to recommend top N similar products for a given customer\n",
    "def get_top_similar_products(customer_id, top_n=5):\n",
    "    # Get customer's interactions\n",
    "    customer_interactions = customer_data.loc[customer_data['Customer ID'] == customer_id, 'Interactions'].iloc[0]\n",
    "\n",
    "    # Convert customer interactions into TF-IDF vectors\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    customer_tfidf_matrix = tfidf_vectorizer.fit_transform([','.join(customer_interactions)])\n",
    "\n",
    "    # Convert product descriptions into TF-IDF vectors\n",
    "    product_tfidf_matrix = tfidf_vectorizer.transform(product_data['Description'])\n",
    "\n",
    "    # Calculate cosine similarity between customer interactions and product descriptions\n",
    "    similarity_scores = cosine_similarity(customer_tfidf_matrix, product_tfidf_matrix)\n",
    "\n",
    "    # Get indices of products sorted by similarity score\n",
    "    similar_product_indices = similarity_scores.argsort()[0][::-1]\n",
    "\n",
    "    # Get top N similar products\n",
    "    top_similar_products = product_data.iloc[similar_product_indices[:top_n]][['Product Name', 'Seller Name']]\n",
    "    return top_similar_products\n",
    "\n",
    "# Function to save recommendations to CSV for a given customer ID\n",
    "def save_recommendations_to_csv(customer_id, recommendations, output_file):\n",
    "    recommendations.to_csv(output_file, index=False)\n",
    "\n",
    "# Ask for customer ID as input\n",
    "customer_id = int(input(\"Enter customer ID: \"))\n",
    "time.sleep(0.5)\n",
    "\n",
    "# Get top 5 similar products for the specified customer\n",
    "similar_products = get_top_similar_products(customer_id)\n",
    "print(\"\\nWe have top 5 products liked by you!\\n\")\n",
    "print(similar_products)\n",
    "\n",
    "# Output file to save recommendations\n",
    "output_file = f\"recommendations_customer.csv\"\n",
    "\n",
    "# Save recommendations to CSV for the specified customer\n",
    "save_recommendations_to_csv(customer_id, similar_products, output_file)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"\\nWait for a while!\\nYour recommendations will be sent to sellers so that you can get personalised offers by them!\\n\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "print(\"Surprise!! Sellers have given you some discounts!!\\n \")\n",
    "\n",
    "%run GreenMart.ipynb\n",
    "\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "\n",
    "def print_csv_file_table(file_path):\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        table_data = [row for row in csv_reader]\n",
    "\n",
    "    # Print the table using tabulate\n",
    "    print(tabulate(table_data, headers='firstrow', tablefmt='fancy_grid'))\n",
    "\n",
    "print_csv_file_table(\"final.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eea9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40343012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
